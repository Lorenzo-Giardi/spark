{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f41d8267190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/iris.csv'\n",
    "df1 = spark.read.format('csv').option('header', 'true').load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sepal_length='5.1', sepal_width='3.5', petal_length='1.4', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='4.9', sepal_width='3.0', petal_length='1.4', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='4.7', sepal_width='3.2', petal_length='1.3', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='4.6', sepal_width='3.1', petal_length='1.5', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='5.0', sepal_width='3.6', petal_length='1.4', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='5.4', sepal_width='3.9', petal_length='1.7', petal_width='0.4', species='setosa'),\n",
       " Row(sepal_length='4.6', sepal_width='3.4', petal_length='1.4', petal_width='0.3', species='setosa'),\n",
       " Row(sepal_length='5.0', sepal_width='3.4', petal_length='1.5', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='4.4', sepal_width='2.9', petal_length='1.4', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='4.9', sepal_width='3.1', petal_length='1.5', petal_width='0.1', species='setosa')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV with no header and automatically infer schema\n",
    "data_path = 'data/iris_nohead.csv'\n",
    "df2 = spark.read.format('csv').option('header', 'false')\\\n",
    "                              .option('inferSchema', 'true')\\\n",
    "                              .load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+------+\n",
      "|_c0|_c1|_c2|_c3|   _c4|\n",
      "+---+---+---+---+------+\n",
      "|5.1|3.5|1.4|0.2|setosa|\n",
      "|4.9|3.0|1.4|0.2|setosa|\n",
      "|4.7|3.2|1.3|0.2|setosa|\n",
      "|4.6|3.1|1.5|0.2|setosa|\n",
      "|5.0|3.6|1.4|0.2|setosa|\n",
      "|5.4|3.9|1.7|0.4|setosa|\n",
      "|4.6|3.4|1.4|0.3|setosa|\n",
      "|5.0|3.4|1.5|0.2|setosa|\n",
      "|4.4|2.9|1.4|0.2|setosa|\n",
      "|4.9|3.1|1.5|0.1|setosa|\n",
      "+---+---+---+---+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumnRenamed('_c0', 'sepal_length') \\\n",
    "         .withColumnRenamed('_c1', 'sepal_width') \\\n",
    "         .withColumnRenamed('_c2', 'petal_length') \\\n",
    "         .withColumnRenamed('_c3', 'petal_width') \\\n",
    "         .withColumnRenamed('_c4', 'species') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/iris.json'\n",
    "df3 = spark.read.json(data_path, multiLine = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|petal_length|petal_width|sepal_length|sepal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         1.4|        0.2|         5.1|        3.5| setosa|\n",
      "|         1.4|        0.2|         4.9|        3.0| setosa|\n",
      "|         1.3|        0.2|         4.7|        3.2| setosa|\n",
      "|         1.5|        0.2|         4.6|        3.1| setosa|\n",
      "|         1.4|        0.2|         5.0|        3.6| setosa|\n",
      "|         1.7|        0.4|         5.4|        3.9| setosa|\n",
      "|         1.4|        0.3|         4.6|        3.4| setosa|\n",
      "|         1.5|        0.2|         5.0|        3.4| setosa|\n",
      "|         1.4|        0.2|         4.4|        2.9| setosa|\n",
      "|         1.5|        0.1|         4.9|        3.1| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/california.csv'\n",
    "df4 = spark.read.option('header', 'True') \\\n",
    "                .option('inferSchema', 'True') \\\n",
    "                .csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income',\n",
       " 'median_house_value',\n",
       " 'ocean_proximity']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5118"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_sampled = df4.sample(False, fraction = 0.25)\n",
    "df4_sampled.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_sorted = df4_sampled.sort('median_house_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6551"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.filter(df4['ocean_proximity']=='INLAND').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2290"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.filter(df4['ocean_proximity']=='NEAR BAY').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|ocean_proximity|count|\n",
      "+---------------+-----+\n",
      "|         ISLAND|    5|\n",
      "|     NEAR OCEAN| 2658|\n",
      "|       NEAR BAY| 2290|\n",
      "|      <1H OCEAN| 9136|\n",
      "|         INLAND| 6551|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.groupBy('ocean_proximity').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------+\n",
      "|ocean_proximity|avg(median_house_value)|\n",
      "+---------------+-----------------------+\n",
      "|         ISLAND|               380440.0|\n",
      "|     NEAR OCEAN|     249433.97742663656|\n",
      "|       NEAR BAY|     259212.31179039303|\n",
      "|      <1H OCEAN|     240084.28546409807|\n",
      "|         INLAND|     124805.39200122119|\n",
      "+---------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.groupBy('ocean_proximity').agg({'median_house_value': 'mean'}).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|median_house_value|\n",
      "+-------+------------------+\n",
      "|  count|             20640|\n",
      "|   mean|206855.81690891474|\n",
      "| stddev|115395.61587441359|\n",
      "|    min|           14999.0|\n",
      "|    max|          500001.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.describe(['median_house_value']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|ocean_proximity|\n",
      "+---------------+\n",
      "|         ISLAND|\n",
      "|     NEAR OCEAN|\n",
      "|       NEAR BAY|\n",
      "|      <1H OCEAN|\n",
      "|         INLAND|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select('ocean_proximity').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.select('ocean_proximity').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880752079585578"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.corr('median_house_value', 'median_income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df4.write.csv('data/df4.csv', 'overwrite')\n",
    "# df4.write.parquet('data/df4', 'overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy36",
   "language": "python",
   "name": "newpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
