{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName('Spark SQL query df') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/lorenzo/spark-repo/1_spark_dataframes/data/california.csv'\n",
    "df = spark.read.option('header', 'True') \\\n",
    "                .option('inferSchema', 'True') \\\n",
    "                .csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
      "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
      "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run SQL queries we need to register a DataFrame as a temporary table, providing it with a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('california')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying a spark dataframe\n",
    "Standard SQL syntax applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------------+\n",
      "|total_rooms|population|median_house_value|\n",
      "+-----------+----------+------------------+\n",
      "|      880.0|     322.0|          452600.0|\n",
      "|     7099.0|    2401.0|          358500.0|\n",
      "|     1467.0|     496.0|          352100.0|\n",
      "|     1274.0|     558.0|          341300.0|\n",
      "|     1627.0|     565.0|          342200.0|\n",
      "+-----------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT total_rooms, population, median_house_value FROM california').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------+-----------+\n",
      "| rooms|population|  rooms_per_person|house_value|\n",
      "+------+----------+------------------+-----------+\n",
      "| 880.0|     322.0| 2.732919254658385|   452600.0|\n",
      "|7099.0|    2401.0|2.9566847147022073|   358500.0|\n",
      "|1467.0|     496.0|2.9576612903225805|   352100.0|\n",
      "|1274.0|     558.0| 2.283154121863799|   341300.0|\n",
      "|1627.0|     565.0| 2.879646017699115|   342200.0|\n",
      "+------+----------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT total_rooms as rooms, \\\n",
    "                  population, \\\n",
    "                  total_rooms/population as rooms_per_person, \\\n",
    "                  median_house_value as house_value \\\n",
    "           FROM california').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+-----------+\n",
      "|rooms|population|    rooms_per_person|house_value|\n",
      "+-----+----------+--------------------+-----------+\n",
      "| 19.0|    7460.0|0.002546916890080429|   137500.0|\n",
      "| 36.0|    4198.0| 0.00857551214864221|    67500.0|\n",
      "|538.0|    8733.0| 0.06160540478644223|   154600.0|\n",
      "|161.0|    1542.0| 0.10440985732814527|   162500.0|\n",
      "| 19.0|     166.0|  0.1144578313253012|   162500.0|\n",
      "+-----+----------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT total_rooms as rooms, \\\n",
    "                  population, \\\n",
    "                  total_rooms/population as rooms_per_person, \\\n",
    "                  median_house_value as house_value \\\n",
    "           FROM california \\\n",
    "           WHERE median_house_value < 200000 \\\n",
    "           ORDER BY rooms_per_person').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+------------------+------------------+------------------+\n",
      "|ocean_proximity|             rooms|   avg(population)|  rooms_per_person|       house_value|\n",
      "+---------------+------------------+------------------+------------------+------------------+\n",
      "|         ISLAND|            1574.6|             668.0|2.3830333305631446|          380440.0|\n",
      "|     NEAR OCEAN| 2583.700902934537|1354.0086531226486|2.0127291274331847|249433.97742663656|\n",
      "|       NEAR BAY| 2493.589519650655|1230.3174672489083|2.0810756094097096|259212.31179039303|\n",
      "|      <1H OCEAN|2628.3435858143607|1520.2904991243433|1.8077601913423533|240084.28546409807|\n",
      "|         INLAND|2717.7427873607085|1391.0462524805373| 2.161737594698368|124805.39200122119|\n",
      "+---------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT ocean_proximity, \\\n",
    "                  mean(total_rooms) as rooms, \\\n",
    "                  mean(population), \\\n",
    "                  mean(total_rooms/population) as rooms_per_person, \\\n",
    "                  mean(median_house_value) as house_value \\\n",
    "           FROM california \\\n",
    "           GROUP BY ocean_proximity').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+-------------------------+----------------+-----------+\n",
      "|ocean_proximity|  rooms|round(avg(population), 2)|rooms_per_person|house_value|\n",
      "+---------------+-------+-------------------------+----------------+-----------+\n",
      "|         ISLAND| 1574.6|                    668.0|            2.38|   380440.0|\n",
      "|     NEAR OCEAN| 2583.7|                  1354.01|            2.01|  249433.98|\n",
      "|       NEAR BAY|2493.59|                  1230.32|            2.08|  259212.31|\n",
      "|      <1H OCEAN|2628.34|                  1520.29|            1.81|  240084.29|\n",
      "|         INLAND|2717.74|                  1391.05|            2.16|  124805.39|\n",
      "+---------------+-------+-------------------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT ocean_proximity, \\\n",
    "                  round(mean(total_rooms), 2) as rooms, \\\n",
    "                  round(mean(population), 2), \\\n",
    "                  round(mean(total_rooms/population), 2) as rooms_per_person, \\\n",
    "                  round(mean(median_house_value), 2) as house_value \\\n",
    "           FROM california \\\n",
    "           GROUP BY ocean_proximity').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct key values: 20434\n"
     ]
    }
   ],
   "source": [
    "df1 = df.withColumn('key', df.latitude + df.longitude +  df.housing_median_age +  df.total_rooms +  df.total_bedrooms +  df.population +  df.households +  df.median_income +  df.median_house_value)\n",
    "print(f\"Distinct key values: {df1.select('key').distinct().count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView('california')\n",
    "df1.createOrReplaceTempView('california_copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = spark.sql('SELECT a.total_rooms as rooms, \\\n",
    "                              a.population, \\\n",
    "                              a.median_house_value as a_house_value, \\\n",
    "                              b.median_house_value as b_house_value \\\n",
    "                       FROM california as a \\\n",
    "                       INNER JOIN california_copy as b \\\n",
    "                       on a.key = b.key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------+-------------+\n",
      "| rooms|population|a_house_value|b_house_value|\n",
      "+------+----------+-------------+-------------+\n",
      "| 880.0|     322.0|     452600.0|     452600.0|\n",
      "|7099.0|    2401.0|     358500.0|     358500.0|\n",
      "|1467.0|     496.0|     352100.0|     352100.0|\n",
      "|1274.0|     558.0|     341300.0|     341300.0|\n",
      "|1627.0|     565.0|     342200.0|     342200.0|\n",
      "+------+----------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20433"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates and NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows that are duplicate on ALL columns\n",
    "df1.drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20434"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows that are duplicate on specified columns\n",
    "df1.drop_duplicates(['key']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|        0|       0|                 0|          0|             0|         0|         0|            0|                 0|              0|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df1.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20433"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+--------+------+----------+-------------+\n",
      "| key|longitude|latitude| rooms|population|a_house_value|\n",
      "+----+---------+--------+------+----------+-------------+\n",
      "|null|  -122.16|   37.77|1256.0|     570.0|     161900.0|\n",
      "|null|  -122.17|   37.75| 992.0|     732.0|      85100.0|\n",
      "|null|  -122.28|   37.78|5154.0|    3741.0|     173400.0|\n",
      "|null|  -122.24|   37.75| 891.0|     384.0|     247100.0|\n",
      "|null|   -122.1|   37.69| 746.0|     387.0|     178400.0|\n",
      "|null|  -122.14|   37.67|3342.0|    1635.0|     186900.0|\n",
      "|null|  -121.77|   39.66|3759.0|    1705.0|     158600.0|\n",
      "|null|  -121.95|   38.03|5526.0|    3207.0|     143100.0|\n",
      "|null|  -121.98|   37.96|2987.0|    1420.0|     204100.0|\n",
      "|null|  -122.01|   37.94|3741.0|    1339.0|     322300.0|\n",
      "+----+---------+--------+------+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT key, \\\n",
    "                  longitude, \\\n",
    "                  latitude, \\\n",
    "                  total_rooms as rooms, \\\n",
    "                  population, \\\n",
    "                  median_house_value as a_house_value \\\n",
    "           FROM california \\\n",
    "           WHERE key is null').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     207|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT count(*) \\\n",
    "           FROM california \\\n",
    "           WHERE key is null').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy36",
   "language": "python",
   "name": "newpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
