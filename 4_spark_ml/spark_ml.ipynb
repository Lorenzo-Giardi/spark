{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/lorenzo/Desktop/utilization.csv'\n",
    "\n",
    "df = spark.read.option('header', 'False') \\\n",
    "                .option('inferSchema', 'True') \\\n",
    "                .csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"_c0\", \"event_datetime\") \\\n",
    "            .withColumnRenamed (\"_c1\", \"server_id\") \\\n",
    "            .withColumnRenamed(\"_c2\", \"cpu_utilization\") \\\n",
    "            .withColumnRenamed(\"_c3\", \"free_memory\") \\\n",
    "            .withColumnRenamed(\"_c4\", \"session_count\")\n",
    "\n",
    "df.createOrReplaceTempView('utilization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=['cpu_utilization', 'free_memory', 'session_count'], \n",
    "                              outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcluster_df = va.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+----------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|        features|\n",
      "+-------------------+---------+---------------+-----------+-------------+----------------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|[0.57,0.51,47.0]|\n",
      "|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|[0.47,0.62,43.0]|\n",
      "|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|[0.56,0.57,62.0]|\n",
      "|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|[0.57,0.56,50.0]|\n",
      "|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|[0.35,0.46,43.0]|\n",
      "+-------------------+---------+---------------+-----------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vcluster_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means clustering\n",
    "Spark ML library implementation of Kmeans expects to find a **features** column in the dataset that is provided to the fit function. This column should be the result of a vector assembler transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans().setK(3).setSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_output = km.fit(vcluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.52047775,  0.47836303, 51.79927162]),\n",
       " array([ 0.71931575,  0.28104316, 88.23965784]),\n",
       " array([ 0.62881549,  0.37094643, 70.43030159])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_output.clusterCenters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+-----------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|   features|\n",
      "+-------------------+---------+---------------+-----------+-------------+-----------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|[0.57,0.51]|\n",
      "|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|[0.47,0.62]|\n",
      "|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|[0.56,0.57]|\n",
      "|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|[0.57,0.56]|\n",
      "|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|[0.35,0.46]|\n",
      "+-------------------+---------+---------------+-----------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va = VectorAssembler(inputCols=['cpu_utilization', 'free_memory'], \n",
    "                              outputCol = 'features')\n",
    "reg_df = va.transform(df)\n",
    "reg_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='features', labelCol='session_count')\n",
    "lr_output = lr.fit(reg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([32.0832, -31.8455])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_output.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.761499518865996"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_output.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3424214623841483"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_output.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.04258233312084"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_output.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy36",
   "language": "python",
   "name": "newpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
